{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = '/shared_space/project_0/rain_gauges/PE_2019_6.csv'\n",
    "X = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "municipio;codEstacao;uf;nomeEstacao;latitude;longitude;datahora;valorMedida\n"
     ]
    }
   ],
   "source": [
    "for thing in X:\n",
    "    print(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X['municipio;codEstacao;uf;nomeEstacao;latitude;longitude;datahora;valorMedida']\n",
    "datapred = []\n",
    "for thing in data:\n",
    "    datapred.append(thing.split(';')[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251589\n",
      "8\n",
      "there are 251589 rows and 8 columns\n"
     ]
    }
   ],
   "source": [
    "print(len(datapred))\n",
    "print(len(datapred[0]))\n",
    "print('there are 251589 rows and 8 columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for thing in datapred:\n",
    "    temp.append(thing[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "temp = np.unique(temp)\n",
    "temp = list(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n",
      "there are 283 stations for rain gauages in total\n"
     ]
    }
   ],
   "source": [
    "print(len(temp))\n",
    "print('there are 283 stations for rain gauages in total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to create a dictionary of all the data with respect to different rain gauges\n",
    "dataf = {}\n",
    "\n",
    "for i in range(len(temp)):\n",
    "    tmp = []\n",
    "    for thing in datapred:\n",
    "        if thing[1] == temp[i]:\n",
    "            tmp.append(thing[0:])\n",
    "    dataf[temp[i]] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a list of the code for each site\n",
    "sites = ['260005401A', '260005402A', '260010401A', '260020301A', '260030201A', '260040102A', '260050001A', '260050002A', '260060901U', '260070801A', '260080701A', '260080701C', '260080702A', '260090601A', '260100301A', '260105201A', '260110201A', '260120101C', '260130001A', '260130002A', '260140901A', '260140902A', '260140903A', '260150802A', '260170601C', '260180501A', '260190401A', '260190401C', '260210001C', '260230801A', '260240701C', '260250601A', '260260501C', '260270401A', '260280301A', '260290202A', '260290203A', '260290204A', '260290205A', '260300901A', '260300901C', '260310801A', '260310802A', '260320701A', '260320701C', '260330601A', '260345401A', '260345402A', '260345403A', '260345404A', '260345405A', '260345406A', '260350401A', '260360301A', '260380101A', '260390001C', '260410601A', '260410602A', '260410603A', '260410605A', '260410606A', '260410607A', '260410608A', '260415501A', '260420502A', '260420503A', '260420504A', '260440301A', '260450201A', '260460101A', '260470001A', '260470001C', '260480901A', '260480902A', '260490801A', '260510301A', '260515201A', '260515201C', '260520201A', '260520202A', '260540001A', '260550901A', '260560801A', '260560801C', '260570701A', '260570702A', '260580601C', '260590501A', '260590502A', '260610101A', '260610102A', '260620001A', '260620002A', '260620003A', '260630901C', '260640801C', '260650701A', '260660601A', '260660601C', '260680403A', '260680404A', '260680405A', '260680406A', '260690301C', '260710901U', '260720801A', '260720802A', '260720803A', '260720804A', '260730701A', '260730703A', '260740601C', '260750501U', '260760401A', '260765301A', '260765302A', '260770301A', '260775201A', '260780201A', '260790101A', '260790102A', '260790103A', '260790104A', '260790106A', '260790107A', '260790108A', '260790109A', '260790110A', '260795001A', '260795002A', '260795004H', '260800801C', '260805701C', '260820602A', '260830501A', '260840401A', '260840401C', '260845301A', '260850301A', '260860201A', '260870101A', '260875001A', '260880001A', '260880001C', '260890901A', '260900601A', '260910501A', '260920401A', '260920402A', '260930301C', '260940201A', '260940202A', '260950101A', '260950102A', '260950103A', '260950104A', '260960001A', '260960002A', '260960003A', '260960004A', '260960005A', '260970901C', '260980801A', '260980801C', '260990701C', '261000402A', '261010301A', '261020201A', '261030101A', '261040001A', '261040001C', '261040002A', '261050901A', '261060801A', '261060802A', '261070702A', '261070703A', '261070704A', '261070705A', '261070706A', '261080601A', '261080601C', '261090501C', '261110101A', '261110101C', '261110102A', '261110102C', '261110103A', '261110103C', '261110104A', '261110105A', '261110106A', '261120001A', '261130901A', '261130902A', '261140801A', '261140802A', '261150701A', '261150702A', '261150704A', '261153301A', '261160601A', '261160603A', '261160604A', '261160605A', '261160606A', '261160607A', '261160608A', '261160609A', '261160610A', '261160613A', '261160614A', '261160615A', '261160617A', '261160618A', '261160619A', '261160620A', '261160621A', '261160622A', '261160623A', '261180401A', '261180402A', '261190301A', '261190302A', '261190303A', '261200001A', '261210901C', '261230701A', '261240601A', '261240601C', '261240602A', '261245501C', '261247101A', '261250501A', '261250501U', '261270301A', '261290101A', '261290102A', '261310701A', '261320601A', '261330501A', '261330501U', '261330502A', '261340401A', '261350301A', '261350302A', '261360201C', '261370101A', '261370102A', '261370103A', '261370104A', '261370105A', '261380001A', '261390901C', '261400601U', '261410501A', '261410501C', '261420401A', '261420402A', '261430301A', '261470901A', '261470902A', '261480801C', '261485701A', '261485702A', '261500301C', '261520101A', '261520101C', '261530001A', '261530002A', '261540901A', '261550801A', '261570601A', '261590401C', '261600101C', '261630801A', '261630802A', '261640702A', '261640703A', '261640704A', '261640705A', '261650601A', '261650602A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n"
     ]
    }
   ],
   "source": [
    "print(len(sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4320\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "#This is the preparation for filling all the missing values in the original dataset\n",
    "idate = datetime.datetime(2019, 5, 31, 23, 50, 0)\n",
    "fdate = datetime.datetime(2019, 6, 30, 23, 40, 0)\n",
    "dt = datetime.timedelta(minutes = 10)\n",
    "date = idate\n",
    "dates = []\n",
    "\n",
    "while date <= fdate:\n",
    "    date = date + dt\n",
    "    dates.append(str(date))\n",
    "print(len(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012\n"
     ]
    }
   ],
   "source": [
    "#This is just used as an reference for the index of each variable\n",
    "print(len(dataf[sites[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of stations now in gaugedates is: 283\n",
      "The number of dates for the first station is: 1012\n"
     ]
    }
   ],
   "source": [
    "gaugedates = []\n",
    "\n",
    "for i in range(len(sites)):\n",
    "    tmp = []\n",
    "    for thing in dataf[sites[i]]:\n",
    "        #gaugedates.append(thing[-2][:-2])\n",
    "        tmp.append(thing[-2][:-2])\n",
    "    gaugedates.append(tmp)\n",
    "#print(len(gaugedates))\n",
    "print('The number of stations now in gaugedates is:', len(gaugedates))\n",
    "print('The number of dates for the first station is:', len(gaugedates[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdates = []\n",
    "for i in range(len(gaugedates)):\n",
    "    tmp = []\n",
    "    for thing in dates:\n",
    "        if thing not in gaugedates[i]:\n",
    "            #missingdates.append(thing)\n",
    "            tmp.append(thing)\n",
    "    missingdates.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdata = []\n",
    "for i in range(len(missingdates)):\n",
    "    tmp = []\n",
    "    for missingdate in missingdates[i]:\n",
    "        #missingdata.append(['ABREU E LIMA', '260005401A', 'PE', 'Distrito Industrial - Timbó', '-34.898', '-7.917', '%s'%missingdate+'.0', '0.00'])\n",
    "        tmp.append(['%s'%dataf[sites[i]][0][0], '%s'%sites[i], 'PE', '%s'%dataf[sites[i]][0][3], '%s'%dataf[sites[i]][0][4], '%s'%dataf[sites[i]][0][5], '%s'%missingdate+'.0', '0.00'])\n",
    "    missingdata.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4320\n",
      "283\n"
     ]
    }
   ],
   "source": [
    "def takenegativeSecond(elem):\n",
    "    return elem[-2]\n",
    "\n",
    "combinedlist = []\n",
    "for i in range(len(missingdata)):\n",
    "    tmp = dataf[sites[i]]\n",
    "    tmp = tmp + missingdata[i]\n",
    "    tmp.sort(key = takenegativeSecond)\n",
    "    combinedlist.append(tmp)\n",
    "print(len(combinedlist[0]))\n",
    "print(len(combinedlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "valuef = []\n",
    "for subcombinedlist in combinedlist:\n",
    "    tmp = []\n",
    "    for thing in subcombinedlist:\n",
    "        tmp.append(float(thing[-1]))\n",
    "    valuef.append(tmp)\n",
    "print(sum(valuef[0][0:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datehourf = []\n",
    "for subcombinedlist in combinedlist:\n",
    "    tmp = []\n",
    "    for thing in subcombinedlist:\n",
    "        tmp.append(thing[-2])\n",
    "    datehourf.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4320\n"
     ]
    }
   ],
   "source": [
    "print(len(datehourf[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1222560\n"
     ]
    }
   ],
   "source": [
    "newcombinedlist = []\n",
    "for thing in combinedlist:\n",
    "    newcombinedlist += thing\n",
    "city = []\n",
    "stationcode = []\n",
    "state = []\n",
    "stationname = []\n",
    "latitude = []\n",
    "longtitude = []\n",
    "datehour = []\n",
    "value = []\n",
    "for thing in newcombinedlist:\n",
    "    city.append(thing[0])\n",
    "    stationcode.append(thing[1])\n",
    "    state.append(thing[2])\n",
    "    stationname.append(thing[3])\n",
    "    latitude.append(thing[4])\n",
    "    longtitude.append(thing[5])\n",
    "    datehour.append(thing[6])\n",
    "    value.append(thing[7])\n",
    "print(len(newcombinedlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.DataFrame({'City': city,'Stationcode': stationcode,'State': state,'Stationname': stationname,'Latitude': latitude,'Longtitude': longtitude,'Datehour': datehour,'Value': value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = dataset.to_csv('/shared_space/project_0/rain_gauges/processed_june.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1263312\n",
      "[0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(4464*283)\n",
    "print(valuef[0][1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "accum30 = []\n",
    "for i in range(len(sites)):\n",
    "    n = 1\n",
    "    f = 4\n",
    "    temp = []\n",
    "    while f <= 4320+3:\n",
    "        temp.append(['%s'%dataf[sites[i]][0][0], '%s'%sites[i], 'PE', '%s'%dataf[sites[i]][0][3], '%s'%dataf[sites[i]][0][4], '%s'%dataf[sites[i]][0][5], '%s'%datehourf[i][n]+'.0', '%s'%sum(valuef[i][n:f])])\n",
    "        n += 3\n",
    "        f += 3\n",
    "    accum30.append(temp)\n",
    "\n",
    "newaccum30 = []\n",
    "for thing in accum30:\n",
    "    newaccum30 += thing\n",
    "city30 = []\n",
    "stationcode30 = []\n",
    "state30 = []\n",
    "stationname30 = []\n",
    "latitude30 = []\n",
    "longtitude30 = []\n",
    "datehour30 = []\n",
    "value30 = []\n",
    "for thing in newaccum30:\n",
    "    city30.append(thing[0])\n",
    "    stationcode30.append(thing[1])\n",
    "    state30.append(thing[2])\n",
    "    stationname30.append(thing[3])\n",
    "    latitude30.append(thing[4])\n",
    "    longtitude30.append(thing[5])\n",
    "    datehour30.append(thing[6])\n",
    "    value30.append(thing[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407520\n",
      "407520\n",
      "2231.0\n",
      "1440\n"
     ]
    }
   ],
   "source": [
    "print(len(newaccum30))\n",
    "print(len(value30))\n",
    "print(631373/283)\n",
    "print(len(accum30[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset30 = pd.DataFrame({'City': city30,'Stationcode': stationcode30,'State': state30,'Stationname': stationname30,'Latitude': latitude30,'Longtitude': longtitude30,'Datehour': datehour30,'Value': value30})\n",
    "export_csv = dataset30.to_csv('/shared_space/project_0/rain_gauges/accum30_june.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "accum60 = []\n",
    "for i in range(len(sites)):\n",
    "    n = 1\n",
    "    f = 7\n",
    "    temp = []\n",
    "    while f <= 4320+6:\n",
    "        temp.append(['%s'%dataf[sites[i]][0][0], '%s'%sites[i], 'PE', '%s'%dataf[sites[i]][0][3], '%s'%dataf[sites[i]][0][4], '%s'%dataf[sites[i]][0][5], '%s'%datehourf[i][n]+'.0', '%s'%sum(valuef[i][n:f])])\n",
    "        n += 6\n",
    "        f += 6\n",
    "    accum60.append(temp)\n",
    "\n",
    "newaccum60 = []\n",
    "for thing in accum60:\n",
    "    newaccum60 += thing\n",
    "city60 = []\n",
    "stationcode60 = []\n",
    "state60 = []\n",
    "stationname60 = []\n",
    "latitude60 = []\n",
    "longtitude60 = []\n",
    "datehour60 = []\n",
    "value60 = []\n",
    "for thing in newaccum60:\n",
    "    city60.append(thing[0])\n",
    "    stationcode60.append(thing[1])\n",
    "    state60.append(thing[2])\n",
    "    stationname60.append(thing[3])\n",
    "    latitude60.append(thing[4])\n",
    "    longtitude60.append(thing[5])\n",
    "    datehour60.append(thing[6])\n",
    "    value60.append(thing[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203760\n",
      "203760\n",
      "892.0\n",
      "720\n"
     ]
    }
   ],
   "source": [
    "print(len(newaccum60))\n",
    "print(len(value60))\n",
    "print(252436/283)\n",
    "print(len(accum60[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset60 = pd.DataFrame({'City': city60,'Stationcode': stationcode60,'State': state60,'Stationname': stationname60,'Latitude': latitude60,'Longtitude': longtitude60,'Datehour': datehour60,'Value': value60})\n",
    "export_csv = dataset60.to_csv('/shared_space/project_0/rain_gauges/accum60_june.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumday = []\n",
    "for i in range(len(sites)):\n",
    "    n = 1\n",
    "    f = 145\n",
    "    temp = []\n",
    "    while f <= 4320+144:\n",
    "        temp.append(['%s'%dataf[sites[i]][0][0], '%s'%sites[i], 'PE', '%s'%dataf[sites[i]][0][3], '%s'%dataf[sites[i]][0][4], '%s'%dataf[sites[i]][0][5], '%s'%datehourf[i][n]+'.0', '%s'%sum(valuef[i][n:f])])\n",
    "        n += 144\n",
    "        f += 144\n",
    "    accumday.append(temp)\n",
    "\n",
    "newaccumday = []\n",
    "for thing in accumday:\n",
    "    newaccumday += thing\n",
    "cityday = []\n",
    "stationcodeday = []\n",
    "stateday = []\n",
    "stationnameday = []\n",
    "latitudeday = []\n",
    "longtitudeday = []\n",
    "datehourday = []\n",
    "valueday = []\n",
    "for thing in newaccumday:\n",
    "    cityday.append(thing[0])\n",
    "    stationcodeday.append(thing[1])\n",
    "    stateday.append(thing[2])\n",
    "    stationnameday.append(thing[3])\n",
    "    latitudeday.append(thing[4])\n",
    "    longtitudeday.append(thing[5])\n",
    "    datehourday.append(thing[6])\n",
    "    valueday.append(thing[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8490\n",
      "8490\n",
      "31.0\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(newaccumday))\n",
    "print(len(valueday))\n",
    "print(8773/283)\n",
    "print(len(accumday[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "datasetday = pd.DataFrame({'City': cityday,'Stationcode': stationcodeday,'State': stateday,'Stationname': stationnameday,'Latitude': latitudeday,'Longtitude': longtitudeday,'Datehour': datehourday,'Value': valueday})\n",
    "export_csv = datasetday.to_csv('/shared_space/project_0/rain_gauges/accumday_june.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABREU E LIMA', '260005401A', 'PE', 'Distrito Industrial - Timbó', '-34.898', '-7.917', '2019-06-30 23:10:00.0.0', '0.78']\n"
     ]
    }
   ],
   "source": [
    "print(accum60[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "testaaa = []\n",
    "for thing in accumday[0]:\n",
    "    temp = []\n",
    "    temp.append(thing[3])\n",
    "    temp.append(thing[-2])\n",
    "    temp.append(thing[-1])\n",
    "    testaaa.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Distrito Industrial - Timbó', '2019-06-01 00:10:00.0.0', '0.39'], ['Distrito Industrial - Timbó', '2019-06-02 00:10:00.0.0', '0.0'], ['Distrito Industrial - Timbó', '2019-06-03 00:10:00.0.0', '0.79'], ['Distrito Industrial - Timbó', '2019-06-04 00:10:00.0.0', '5.710000000000001'], ['Distrito Industrial - Timbó', '2019-06-05 00:10:00.0.0', '0.5900000000000001'], ['Distrito Industrial - Timbó', '2019-06-06 00:10:00.0.0', '7.720000000000001'], ['Distrito Industrial - Timbó', '2019-06-07 00:10:00.0.0', '0.0'], ['Distrito Industrial - Timbó', '2019-06-08 00:10:00.0.0', '1.19'], ['Distrito Industrial - Timbó', '2019-06-09 00:10:00.0.0', '0.79'], ['Distrito Industrial - Timbó', '2019-06-10 00:10:00.0.0', '0.0'], ['Distrito Industrial - Timbó', '2019-06-11 00:10:00.0.0', '6.6000000000000005'], ['Distrito Industrial - Timbó', '2019-06-12 00:10:00.0.0', '2.1799999999999997'], ['Distrito Industrial - Timbó', '2019-06-13 00:10:00.0.0', '130.64'], ['Distrito Industrial - Timbó', '2019-06-14 00:10:00.0.0', '13.989999999999998'], ['Distrito Industrial - Timbó', '2019-06-15 00:10:00.0.0', '0.6000000000000001'], ['Distrito Industrial - Timbó', '2019-06-16 00:10:00.0.0', '56.88000000000004'], ['Distrito Industrial - Timbó', '2019-06-17 00:10:00.0.0', '58.62000000000004'], ['Distrito Industrial - Timbó', '2019-06-18 00:10:00.0.0', '57.480000000000004'], ['Distrito Industrial - Timbó', '2019-06-19 00:10:00.0.0', '0.4'], ['Distrito Industrial - Timbó', '2019-06-20 00:10:00.0.0', '3.5500000000000003'], ['Distrito Industrial - Timbó', '2019-06-21 00:10:00.0.0', '0.0'], ['Distrito Industrial - Timbó', '2019-06-22 00:10:00.0.0', '0.0'], ['Distrito Industrial - Timbó', '2019-06-23 00:10:00.0.0', '0.0'], ['Distrito Industrial - Timbó', '2019-06-24 00:10:00.0.0', '0.0'], ['Distrito Industrial - Timbó', '2019-06-25 00:10:00.0.0', '0.0'], ['Distrito Industrial - Timbó', '2019-06-26 00:10:00.0.0', '0.0'], ['Distrito Industrial - Timbó', '2019-06-27 00:10:00.0.0', '0.0'], ['Distrito Industrial - Timbó', '2019-06-28 00:10:00.0.0', '0.0'], ['Distrito Industrial - Timbó', '2019-06-29 00:10:00.0.0', '0.0'], ['Distrito Industrial - Timbó', '2019-06-30 00:10:00.0.0', '3.9300000000000006']]\n"
     ]
    }
   ],
   "source": [
    "print(testaaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
